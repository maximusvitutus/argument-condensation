{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a prompt template that is populated with political comments on a given topic. \n",
    "\n",
    "Output is a list of Argument entities.\n",
    "\n",
    "Config as needed by altering main() at the bottom of the file. \n",
    "\n",
    "Not iterative; not capable of processing in multiple batches with addition & synthesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "# Get the absolute path to the parent directory (assumes this file is in 'condensation')\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from chatbot_api.providers.openai import OpenAIProvider\n",
    "from chatbot_api.base import Role, Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Argument:\n",
    "    def __init__(self, main_point: str, subpoints: List[str], score_distribution: List[int], source_indices: List[int]):\n",
    "        self.main_point = main_point                 # The main argument which is a broad, high-level point\n",
    "        self.subpoints = subpoints                   # Supporting subpoints\n",
    "        self.score_distribution = score_distribution # Likert score distribution\n",
    "        self.source_indices = source_indices         # Indices of the source comments that support the argument (at least in some way)\n",
    "\n",
    "class ArgumentProcessor:\n",
    "    def __init__(self, llm_provider: OpenAIProvider, batch_size: int):\n",
    "        self.llm_provider = llm_provider\n",
    "        self.batch_size = batch_size # currently not used. to do: implement batching and iterative processing\n",
    "        self.PROMPT_TEMPLATE = \"\"\"\n",
    "            ### Instructions:\n",
    "            1. Review the following numbered comments on the topic: \"{topic}\"\n",
    "            2. **Identify and categorize arguments into main topics**.\n",
    "                - Main arguments are broad, high-level points.\n",
    "                - Subpoints provide supporting details or reasoning for the main argument.\n",
    "            3. Avoid redundancy by combining similar arguments or subpoints. Avoiding redundancy applies to the content of arguments, not to the source indices.\n",
    "            4. For each argument and subpoint, include the indices of the source comments in square brackets, as shown in the output format below.\n",
    "            5. Ensure each argument includes source indices which keep track of the comments that support the argument.\n",
    "            6. Provide the output in Finnish.\n",
    "            7. Ensure that no argument is repeated, and that each is categorized correctly, avoiding redundancy.\n",
    "            8. Make sure that you include all the comment indices that you have used in synthesising the arguments.\n",
    "            9. Accurate index tracking is a critical task, so ensure that you are not missing any comments that support the argument.\n",
    "            \n",
    "            ### Output Format: \n",
    "            <ARGUMENTS>\n",
    "            MAIN: [Main Argument] [source_indices: 1,2,3]\n",
    "            SUB: [Supporting subpoint] [source_indices: 1,2]\n",
    "            SUB: [Another supporting subpoint] [source_indices: 3]\n",
    "            </ARGUMENTS>\n",
    "\n",
    "            ### Comments to analyze:\n",
    "            {comments_text}\n",
    "            \"\"\"\n",
    "\n",
    "    def get_relevant_scores(self, indices: List[int], all_likert_scores: List[int]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Get the Likert scores for the given indices from the full list of scores.\n",
    "        \n",
    "        Args:\n",
    "            indices: List of indices for which to get scores\n",
    "            all_likert_scores: Complete list of Likert scores\n",
    "            \n",
    "        Returns:\n",
    "            List of Likert scores corresponding to the given indices\n",
    "        \"\"\"\n",
    "        return [all_likert_scores[idx] for idx in indices if idx < len(all_likert_scores)]\n",
    "\n",
    "    def calculate_score_distribution(self, scores: List[int]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Calculate the distribution of Likert scores (as percentages).\n",
    "        \n",
    "        Args:\n",
    "            scores: List of Likert scores (1-5)\n",
    "            \n",
    "        Returns:\n",
    "            List of 5 ints representing the percentage distribution of scores\n",
    "        \"\"\"\n",
    "        if not scores:\n",
    "            return [0] * 5\n",
    "            \n",
    "        distribution = [0] * 5\n",
    "        for score in scores:\n",
    "            if 1 <= score <= 5:  # Assuming Likert scale 1-5\n",
    "                distribution[int(score-1)] += 1\n",
    "                \n",
    "        total = sum(distribution)\n",
    "        return [count for count in distribution] if total > 0 else [0] * 5\n",
    "\n",
    "    async def _create_initial_prompt(self, comments: List[str], indices: List[int], topic: str) -> str:\n",
    "        \"\"\"\n",
    "        Create the initial prompt for the argument generation task with max number of comments that fit in the prompt.\n",
    "        Returns the prompt and the number of comments that fit in the prompt.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the number of comments that fit in the prompt\n",
    "        # Note: Using the full context length makes reliable index tracking impossible (missing comments).\n",
    "        # TO DO: Use a context length that allows for reliable index tracking.\n",
    "        fit_count = await self.llm_provider.fit_comment_args_count(comments, self.PROMPT_TEMPLATE.format(topic=topic, comments_text=\"\")) # populate with topic and dummy comment text\n",
    "        \n",
    "        if fit_count == 0:\n",
    "            raise ValueError(\"No comments fit in the prompt.\")\n",
    "\n",
    "        # Take only the messages that fit\n",
    "        comments = comments[:fit_count]\n",
    "        indices = indices[:fit_count]\n",
    "\n",
    "        numbered_comments = [f\"[{idx}] {comment}\" for idx, comment in zip(indices, comments)]\n",
    "        comments_text = \"\\n\".join(numbered_comments)\n",
    "\n",
    "        return self.PROMPT_TEMPLATE.format(topic=topic, comments_text=comments_text), fit_count\n",
    "\n",
    "    async def _parse_arguments(self, response: str, likert_answers: List[int]) -> List[Argument]:\n",
    "        arguments = []\n",
    "        current_main = None\n",
    "        current_subpoints = []\n",
    "        current_indices = set()\n",
    "        \n",
    "        pattern = r'<ARGUMENTS>(.*?)</ARGUMENTS>'\n",
    "        match = re.search(pattern, response, re.DOTALL)\n",
    "        if not match:\n",
    "            return arguments\n",
    "            \n",
    "        lines = match.group(1).strip().split('\\n')\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "                \n",
    "            indices_match = re.search(r'\\[source_indices: ([\\d,\\s]+)\\]', line)\n",
    "            indices = [int(idx.strip()) for idx in indices_match.group(1).split(',')] if indices_match else []\n",
    "            \n",
    "            content = re.sub(r'\\[source_indices: [\\d,\\s]+\\]', '', line).strip()\n",
    "            \n",
    "            if line.startswith('MAIN:'):\n",
    "                if current_main is not None:\n",
    "                    relevant_scores = self.get_relevant_scores(list(current_indices), likert_answers)\n",
    "                    score_distribution = self.calculate_score_distribution(relevant_scores)\n",
    "                    arguments.append(Argument(\n",
    "                        main_point=current_main,\n",
    "                        subpoints=current_subpoints,\n",
    "                        score_distribution=score_distribution,\n",
    "                        source_indices=list(current_indices)\n",
    "                    ))\n",
    "                \n",
    "                current_main = content.replace('MAIN:', '').strip()\n",
    "                current_subpoints = []\n",
    "                current_indices = set(indices)\n",
    "                \n",
    "            elif line.startswith('SUB:'):\n",
    "                subpoint = content.replace('SUB:', '').strip()\n",
    "                current_subpoints.append(subpoint)\n",
    "                current_indices.update(indices)\n",
    "        \n",
    "        # Add the last argument\n",
    "        if current_main is not None:\n",
    "            relevant_scores = self.get_relevant_scores(list(current_indices), likert_answers)\n",
    "            score_distribution = self.calculate_score_distribution(relevant_scores)\n",
    "            arguments.append(Argument(\n",
    "                main_point=current_main,\n",
    "                subpoints=current_subpoints,\n",
    "                score_distribution=score_distribution,\n",
    "                source_indices=list(current_indices)\n",
    "            ))\n",
    "            \n",
    "        return arguments\n",
    "\n",
    "    async def process_batch(self, comments: List[str], comment_indices: List[int], topic: str, likert_answers: List[int] = None) -> List[Argument]:\n",
    "        '''\n",
    "        Process a batch of comments and generate arguments.\n",
    "        Returns a list of Argument objects and the number of comments that were used.\n",
    "        '''\n",
    "        prompt, n_comments_used = await self._create_initial_prompt(comments, comment_indices, topic) # gets the max number of comments that fit in the prompt\n",
    "        response = await self.llm_provider.generate([Message(Role.USER, prompt)])\n",
    "        \n",
    "        # Parse arguments and calculate distributions in one step\n",
    "        arguments = await self._parse_arguments(response.content, likert_answers if likert_answers else [])\n",
    "        return arguments, n_comments_used\n",
    "\n",
    "    async def format_arguments(self, arguments: List[Argument]) -> str:\n",
    "        formatted_output = [\"-\" * 50]\n",
    "        for i, arg in enumerate(arguments, 1):\n",
    "            formatted_output.append(f\"Argument {i}: {arg.main_point}\\n\")\n",
    "            \n",
    "            if arg.subpoints:\n",
    "                formatted_output.append(\"Supporting points:\")\n",
    "                for j, subpoint in enumerate(arg.subpoints, 1):\n",
    "                    formatted_output.append(f\"  {j}. {subpoint}\")\n",
    "            \n",
    "            if arg.score_distribution:\n",
    "                formatted_output.append(\"\\nLikert Score Distribution (calculated from indices given by the LLM):\")\n",
    "                for score_nominality, prevalence in enumerate(arg.score_distribution, 1):\n",
    "                    formatted_output.append(f\"  Score {score_nominality}: {prevalence:} answers\")\n",
    "\n",
    "            formatted_output.append(f\"\\nSource indices: {arg.source_indices}\\n\")\n",
    "            \n",
    "            formatted_output.append(\"-\" * 50)\n",
    "        \n",
    "        return \"\\n\".join(formatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument: Menojen karsiminen on ensisijainen tapa tasapainottaa kunnan taloutta, mutta se ei saa vaarantaa peruspalveluita tai kuntalaisten hyvinvointia.\n",
      "From these comments:\n",
      "\n",
      "Säästämisellä ei ole merkitystä, jos perälauta vuotaa. On paikattava perälauta eli nipistettävä investoinnit minimiin ja pidättäydyttävä uusista suurista mammuttihankkeista.\n",
      "\n",
      "\n",
      "Turhat toiminnot on poistettava.\n",
      "Tällaisessa tapauksessa menoja tulisi karsia niin, että kuntalaisten turvallisuus ja peruspalvelut säilyvät. \n",
      "Hallintorakenteet ovat monimutkaisia ja moniportaisia. Yksinkertaistamalla niitä saamme järjestelmämme toimimaan paremmin vaikuttavammin ja tehokkaammin. Säästetään hallinnossa, ei palvelua tekevässä portaassa. Eikä kiristetä verotusta, vaan luodaan työpaikkoja.\n",
      "Tässä on tärkeää, mistä säästetään. Paras säästökohde ovat turhat kiinteistöt.\n",
      "Argument: Veronkorotuksia voidaan harkita, mutta ne tulisi olla viimeinen keino talouden tasapainottamisessa, koska korkea verotus vähentää kuntien vetovoimaa ja asukkaiden ostovoimaa.\n",
      "From these comments:\n",
      "\n",
      "Yleensäkin verotus on Suomessa suunnilleen korkein mahdollinen. Verojen nosto huonontaa työllisyyttä ja ostovoimaa ja on mahdollista, että tällä verotuksen tasolla verotuotto voi alkaa laskea tai verojen nosto on saman tien kompensoitava maksamalla erilaisia tukia, jolloin valtiolle jäävä raha ei lisäänny.\n",
      "Kestävä tapa verotulojen kasvattamiseen ja edelleen talouden tasapainottamiseen on työllisyysasteen nostaminen ja työn tuottavuuden parantaminen.\n",
      "Kyllä menoleikkauksia on löydyttävä. Verojen korotusten tie alkaa olla loppuun käyty.\n",
      "Kyllä aivan totta, koska veroja kiristämällä vähäosaisten eläminen kiristyy entisestään.\n",
      "Kotkassa on jo korkea kunnallisvero.\n",
      "Argument: Kunnan talouden tasapainottaminen edellyttää rakenteellisia uudistuksia ja toimintatapojen tehostamista.\n",
      "From these comments:\n",
      "\n",
      "Ei ne suuret tulot, vaan pienet menot. Vanha totuus pätee tässäkin. Kaikista mieluiten taloutta tulee tasapainottaa investoimalla kunnan elinkeinoelämään sekä vetovoimaan eli houkuttelemalla kuntaan uusia työnantajia sekä asukkaita - ts. parantamalla tulopohjaa. \n",
      "\n",
      "Mikäli kuitenkin säästöjä olisi tehtävä, niin on hyvä pitää mielessä, että kunnan tehtävät ja palvelurakenne ovat viime vuosina muuttuneet. Näin ollen ensin tulisi tarkastella kunnan palveluita sekä prosesseja: Tehdäänkö varmasti oikeita ja vaikuttavia asioita, kustannustehokkaalla tavalla? Vai tehdäänkö vanhasta muistista vielä myös asioita, joita ei nykyisessä mallissa enää edes tulisi tehdä? Kohdennetaanko niukat resurssit oikeudenmukaisesti? Entä onko prosesseissa paljon hukkaa? \n",
      "\n",
      "Uskon, että ns \"leanaamalla\" on löydettävissä paljon säästöjä ilman, että palveluista joudutaan tinkimään - ja ilman, että veroja kiristetään. Kotkan veroprosentti on jo melko korkea ja vastustan kuntaverotuksen kiristämistä. \n",
      "Vastuullinen kuntatalouden hoito voi olla ja sen tulee olla muutakin kuin välittömiä sopeutustoimia, ts. menojen leikkauksia ja/tai verojen korotuksia. \n",
      "Olen sitoutunut löytämään talouskasvua ja työllisyyttä tukevia rakenneuudistuksia siten, että veroja ei tarvitse nostaa ja menoleikkaukset voidaan minimoida. Ennen kaikkea tarvitaa yrittäjyyttä ja työn tekemistä tukevie toimenpiteitä, jotka tuottavat verotuloja kunnan menojen kattamiseen.\n",
      "\n",
      "Menoja voi kiristää muuttamalla toimintamalleja ja ottamalla käyttöön joustavia palvelukonsepteja. Kaikkia ei kannata enää tehdä \"niinkuin ennen\".\n",
      "Hallintorakenteet ovat monimutkaisia ja moniportaisia. Yksinkertaistamalla niitä saamme järjestelmämme toimimaan paremmin vaikuttavammin ja tehokkaammin. Säästetään hallinnossa, ei palvelua tekevässä portaassa. Eikä kiristetä verotusta, vaan luodaan työpaikkoja.\n",
      "Juuri näin, kaikki menot tulee arvioida - jatkuvasti. Ei ole sellaista kunnan toimintoa, joka olisi tarpeellinen ikuisesti. Palvelun toteutustapaa ja taloutta on arvioitava jatkuvasti. Kaikkea ei tarvitse tehdä kunnan omana toimintana, usein yhteistyömalli kunnan ja yritysten tai kolmannen sektorin kanssa on toimiva ratkaisu. Osa kunnan palveluista on hoidettava omana toimintana, jos sitä ei ole kannattavaa toteuttaa yksitysellä palveluntarjoajalla. \n",
      "Argument: Tulojen lisääminen, esimerkiksi työllistämisen ja elinvoimaisuuden parantamisen kautta, on pitkäjänteinen ja kestävä ratkaisu kuntatalouden tasapainottamiseen.\n",
      "From these comments:\n",
      "\n",
      "Ei ne suuret tulot, vaan pienet menot. Vanha totuus pätee tässäkin. Kaikista mieluiten taloutta tulee tasapainottaa investoimalla kunnan elinkeinoelämään sekä vetovoimaan eli houkuttelemalla kuntaan uusia työnantajia sekä asukkaita - ts. parantamalla tulopohjaa. \n",
      "\n",
      "Mikäli kuitenkin säästöjä olisi tehtävä, niin on hyvä pitää mielessä, että kunnan tehtävät ja palvelurakenne ovat viime vuosina muuttuneet. Näin ollen ensin tulisi tarkastella kunnan palveluita sekä prosesseja: Tehdäänkö varmasti oikeita ja vaikuttavia asioita, kustannustehokkaalla tavalla? Vai tehdäänkö vanhasta muistista vielä myös asioita, joita ei nykyisessä mallissa enää edes tulisi tehdä? Kohdennetaanko niukat resurssit oikeudenmukaisesti? Entä onko prosesseissa paljon hukkaa? \n",
      "\n",
      "Uskon, että ns \"leanaamalla\" on löydettävissä paljon säästöjä ilman, että palveluista joudutaan tinkimään - ja ilman, että veroja kiristetään. Kotkan veroprosentti on jo melko korkea ja vastustan kuntaverotuksen kiristämistä. \n",
      "Laittaisin kursorin keskelle, koska on olemassa kolmaskin tie: jos saamme kuntaamme lisää yrityksiä ja lisää työpaikkoja, kaupungin talous kasvaa ja pystymme hoitamaan myös velvoitteet velkaantumatta. \n",
      "Tärkeää on uusien työpaikkojen luominen ja siten veropohjan laajentaminen, jolloin verotusta ei tarvitse kiristää.\n",
      "Menopuoli on aina oltava tarkastelun alla. Veroja kiristämällä luodaan yrittämiaen ja työnteon kannattavuuden vastaista mielialaa ja johtaa vielä vähempiin verotuloihin pitkällä tähtäyksellä. Työtilaisuuksien luominen luo verotuloja ja myös hyvinvointia\n",
      "Tärkeintä on saada lisää työpaikkoja ja siten veronmaksajia.\n",
      "Argument: Talouden tasapainottaminen ei ole joko-tai-kysymys, vaan se vaatii sekä menojen karsimista että mahdollisesti veronkorotuksia tilanteesta riippuen.\n",
      "From these comments:\n",
      "\n",
      "Mielestäni kaikki vaihtoehdot täytyy olla käytettävissä, kun etsitään keinoja tasapainottaa talous ja löytää kestävän kasvun ura. Paras vaihtoehto löytyy todennäköisesti näitä molempia yhdistelemällä.\n",
      "\n",
      "Pitää katsoa mikä toimenpide kulloinkin on järkevää toteuttaa.\n",
      "Molempia tarvitaan, jos kunta kriisiytyy\n",
      "Menojen karsinta helposti kohdistuu heikompiosaisiin. Näiden vaihtoehtojen välillä olisi löydettävä järkevä tasapaino.\n",
      "Karsittavat menot ja etenkin niiden kerrannaisvaikutukset tulee arvioida tarkkaan.\n"
     ]
    }
   ],
   "source": [
    "# TO DO: get the topic automatically (different file than the data itself), now it is manually set\n",
    "async def main():\n",
    "    # Params\n",
    "    n_comments = 400 # Number of comments to process overall\n",
    "    batch_size = 20 # Number of comments per batch\n",
    "    topic = \"Kun kunnan menoja ja tuloja tasapainotetaan, se on tehtävä mieluummin menoja karsimalla kuin veroja kiristämällä.\"  \n",
    "\n",
    "    # Config\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    model=\"gpt-4o-2024-11-20\"\n",
    "    openai_provider = OpenAIProvider(api_key, model)    \n",
    "    processor = ArgumentProcessor(openai_provider, batch_size)\n",
    "\n",
    "    # Setup paths\n",
    "    data_source_path = os.path.join(parent_dir, 'data', 'sources', 'kuntavaalit2021.csv')\n",
    "    output_path = os.path.join(parent_dir, 'condensation', 'results','results_with_indices', 'version1_iter2.txt')\n",
    "\n",
    "    # Read and prepare data\n",
    "    df = pd.read_csv(data_source_path)\n",
    "\n",
    "    # Choose a subset of comments to process\n",
    "    question_index = 10\n",
    "    explanation_column_name = f'q{question_index}.explanation_fi'\n",
    "    likert_column_name = f'q{question_index}.answer'\n",
    "\n",
    "    # Get comments and their original indices\n",
    "    comment_mask = df[explanation_column_name].notna() # Only process comments with content\n",
    "    comment_indices = df[comment_mask][explanation_column_name].index[:n_comments].tolist() # Get the first n_comments indices\n",
    "    comments = df.loc[comment_indices, explanation_column_name].tolist() \n",
    "    \n",
    "    # Get corresponding Likert scores\n",
    "    likert_answers = df.loc[comment_indices, likert_column_name].tolist()\n",
    "    \n",
    "    # Process arguments\n",
    "    arguments, n_comments_used = await processor.process_batch(\n",
    "        comments=comments,\n",
    "        comment_indices=comment_indices,\n",
    "        topic=topic,\n",
    "        likert_answers=likert_answers\n",
    "    )\n",
    "    \n",
    "    # Format and save results\n",
    "    formatted_args = await processor.format_arguments(arguments)\n",
    "\n",
    "    # For debugging\n",
    "    # check that the arguments and their source indices comments make sense\n",
    "    for arg in arguments:\n",
    "        print(f'Argument: {arg.main_point}')\n",
    "        first_indices = arg.source_indices[:5]\n",
    "        print(f'From these comments:\\n')\n",
    "        for idx in first_indices:\n",
    "            print(df.loc[idx, explanation_column_name])\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Number of comments used: {n_comments_used} out of the attempted {n_comments}\\n\")\n",
    "        f.write(formatted_args)\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
