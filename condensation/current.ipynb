{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "# Get the absolute path to the parent directory (assumes this file is in 'condensation')\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from chatbot_api.providers.openai import OpenAIProvider\n",
    "from chatbot_api.base import Role, Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponderings\n",
    "  (1) hello ponderings\n",
    "  (2) i think it makes sense to make the analysis optional, so that means we need to make the synthesize_batch function return args depending on a flag\n",
    "      - this can be achieved with making the input to the synthesis be Argument class entities\n",
    "  (3) the synthesizer class saves all inputs and outputs! but this should be more granular\n",
    "      - input can be of three different types (init, sync, analysis). ofc we can just use the modulo of the indices to find which one it is, but for future reference i think should be divided with some more intuitive way of differentation. maybe just a ResponseType class with a List of Tuples: \n",
    "      - input_history -> List[((input_type), (str))]\n",
    "          - str = LLM input string, 3 types\n",
    "          - now input_history -> List[str] (where the strings are prompts)\n",
    "      - output_history -> List[(output_type), (str)] \n",
    "          - str = LLM response string, 3 types\n",
    "\n",
    "To Do\n",
    "  (1) extend the parser\n",
    "      - parse which comment indices the the LLM has given, in the analysis output, as sources for the changes \n",
    "      - then use them to show the admin some comments to see if the changes _actually_ make sense \n",
    "  (2) create a smarter flagging system\n",
    "      - currently, we flag using relevance, which measures correlation between old Arguments and new comments\n",
    "      - this is obviously stupid. new comments can have very different opinions than old Args. this ought not be punished.\n",
    "      - it's better to have the LLM do some sort of qualitative analysis on whether the new Arg (or Args, plural) is _better_ or not\n",
    "          - what is _better_, then? \n",
    "          - probably something like \"do these new Args incorporate the ideas from the comments without losing their original information?\"\n",
    "          - maybe just: yes / no for simplicity\n",
    "            - the \"threshold\" can be implicit, it's superfluous to have a relevance score that is just if-elsed out anyway \n",
    "  (3) keep track of some stats / metadata\n",
    "      - stats for how often flagging happens and why\n",
    "      - stats for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Argument:\n",
    "    \"\"\"\n",
    "    A simplified argument class that tracks the main point and its history.\n",
    "    The history allows us to see how the argument evolved over iterations.\n",
    "    \"\"\"\n",
    "    main_argument: str\n",
    "    argument_history: List[str]      # Tracks how this argument has changed over time\n",
    "    latest_relevance_score: int    # The relevance score given by the model in the latest iteration\n",
    "    latest_sources: List[str]        # Tracks the comments that led to the latest update\n",
    "    latest_change: str\n",
    "    latest_change_explained: str\n",
    "\n",
    "    # currently not in use\n",
    "    def update(self, new_arg: str):\n",
    "        \"\"\"Record a new version of this argument.\"\"\"\n",
    "        self.argument_history.append(self.main_argument)\n",
    "        self.main_argument = new_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentFlaggingSystem:\n",
    "    def __init__(self, relevance_threshold: int = 8):\n",
    "        \"\"\"\n",
    "        Initialize the argument flagging system.\n",
    "        \n",
    "        Args:\n",
    "            relevance_threshold: Arguments with relevance scores below this value will be flagged\n",
    "        \"\"\"\n",
    "        self.relevance_threshold = relevance_threshold\n",
    "\n",
    "    def flag_low_relevance_arguments(self, \n",
    "                                   argument_analysis: Dict[str, List[Dict[str, str]]], \n",
    "                                   new_argument_texts: List[str]) -> List[Tuple[str, Dict[str, str]]]:\n",
    "        \"\"\"\n",
    "        Identify arguments with low relevance scores that need admin review.\n",
    "        \n",
    "        Args:\n",
    "            argument_analysis: List of argument analysis dictionaries from batch analysis, \n",
    "                             contains both single argument analysis and an entire batch summary\n",
    "            new_argument_texts: List of new argument main points as strings\n",
    "            \n",
    "        Returns:\n",
    "            List of tuples containing (main_point, metadata) for flagged arguments. Main point is from the initial synthesis output, not the analysis output. \n",
    "        \"\"\"\n",
    "        flagged_arguments = []\n",
    "        \n",
    "        # Extract the arguments analysis from the dictionary\n",
    "        argument_analyses = argument_analysis.get('arguments', [])\n",
    "        print(f'\\nArguments used for flagging:')\n",
    "        for argument in argument_analyses:\n",
    "            print(f\"  Argumentti {argument.get('index')}: {argument.get('argumentaatio')}\")\n",
    "\n",
    "        # TO DO: if the analysis happens to have more arguments (b/c of LLM wonkiness), what do we do? \n",
    "        # Currently, the zip function takes care of this (it's bijective), but is it optimal? at least a warning could be beneficial\n",
    "        # Would also make sense to have some fall back for this... anyway, it's not a huge problem b/c high LLM accuracy\n",
    "        if len(new_argument_texts) != len(argument_analyses):\n",
    "            pass\n",
    "\n",
    "        # Process each new argument and its analysis (PRESUMES THAT THE ORDER OF ARGUMENTS IS THE SAME IN BOTH LISTS, add a check for this)\n",
    "        for input_arg, arg_analysis in zip(new_argument_texts, argument_analyses):\n",
    "            should_flag = False\n",
    "            flag_reason = []\n",
    "            analysis_arg_string = arg_analysis.get('argumentaatio', '') # this is the LLM's latest version of the argument, given in the analysis output\n",
    "\n",
    "            # Check if the argument text has changed\n",
    "            if analysis_arg_string == input_arg:\n",
    "                print(f\"\\n Flagger: an analysis argument matched the input argument\")\n",
    "                print(f\"So, this string stayed the same: {analysis_arg_string}\")\n",
    "                # Text matches a saved argument, check relevance score\n",
    "                try:\n",
    "                    relevance_score = float(arg_analysis.get('relevanttius', '0'))\n",
    "                    print(f\"\\nComparing relevance score of {relevance_score} to threshold {self.relevance_threshold}\")\n",
    "                    if relevance_score < self.relevance_threshold:\n",
    "                        should_flag = True\n",
    "                        flag_reason.append(f\"Low relevance score: {relevance_score}\")\n",
    "                except (ValueError, TypeError) as e:\n",
    "                    should_flag = True\n",
    "                    flag_reason.append(f\"\\nInvalid relevance score format: {e}\")\n",
    "            else:\n",
    "                print(f\"\\n Flagger: an analysis argument didn't match the input argument\")\n",
    "                print(f\"\\nNamely, OUTPUT != INPUT: \")\n",
    "                print(f\"{analysis_arg_string}\")\n",
    "                print(\"!=\")\n",
    "                print(f\"{input_arg}\")\n",
    "                # New or modified argument text\n",
    "                should_flag = True\n",
    "                flag_reason.append(\"New argument is different from the analysis output argument\")\n",
    "\n",
    "            if should_flag:\n",
    "                # Create metadata dictionary for the flagged argument\n",
    "                metadata = {\n",
    "                    \"flag_reason\": flag_reason,\n",
    "                    \"post_analysis_arg\": analysis_arg_string,\n",
    "                    \"relevanttius\": arg_analysis.get('relevanttius', 'Not available'),\n",
    "                    \"jaljitettavyys\": arg_analysis.get('jaljitettavyys', 'Not available'),\n",
    "                    \"muutokset\": arg_analysis.get('muutokset', 'Not available'),\n",
    "                    \"perustelut\": arg_analysis.get('perustelut', 'Not available')\n",
    "                }\n",
    "                flagged_arguments.append((input_arg, metadata))\n",
    "        \n",
    "        return flagged_arguments\n",
    "\n",
    "    async def get_confirmation_from_admin(self, \n",
    "                                        flagged_arguments: List[Tuple[str, Dict[str, str]]]) -> Dict[str, List[Argument]]:\n",
    "        \"\"\"\n",
    "        Present flagged arguments to admin and get confirmation for each.\n",
    "        \n",
    "        Args:\n",
    "            flagged_arguments: List of (main_point, metadata) tuples that need review\n",
    "            \n",
    "        Returns:\n",
    "            List of approved Argument objects\n",
    "        \"\"\"\n",
    "        approved_arguments = []\n",
    "        \n",
    "        if not flagged_arguments:\n",
    "            print(f'\\nFlagged arguments: {flagged_arguments}')\n",
    "            return {\"approved\": approved_arguments, \"rejected\": []}\n",
    "            \n",
    "        print(\"\\n=== Arguments Flagged for Review ===\\n\")\n",
    "        \n",
    "        for main_point, metadata in flagged_arguments:\n",
    "            flag_reason = metadata.get('flag_reason', 'Unknown')\n",
    "            if flag_reason == \"New argument is different from the analysis output argument\":\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"Reviewing Argument: {main_point}\")\n",
    "                print(f\"Reason: {main_point} doesn't match {metadata.get('post_analysis_arg', 'Error: Argument Not available')}\")\n",
    "\n",
    "            else:\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"Reviewing Argument: {main_point}\")\n",
    "                print(f\"Flag Reason: {flag_reason}\")\n",
    "                print(\"\\nAnalysis:\")\n",
    "                print(f\"- Relevance Score: {metadata.get('relevanttius', 'Not available')}\")\n",
    "                print(f\"- Traceability: {metadata.get('jaljitettavyys', 'Not available')}\")\n",
    "                print(f\"- Changes: {metadata.get('muutokset', 'Not available')}\")\n",
    "                print(f\"- Reasoning: {metadata.get('perustelut', 'Not available')}\")\n",
    "                \n",
    "            while True:\n",
    "                response = input(\"\\nAccept this argument for next batch? (y/n): \").lower()\n",
    "                if response in ['y', 'n']:\n",
    "                    break\n",
    "                print(\"Please enter 'y' for yes or 'n' for no.\")\n",
    "            \n",
    "            if response == 'y':\n",
    "                # Parse the sources from traceability text\n",
    "                sources = self._parse_sources(metadata.get('jaljitettavyys', ''))\n",
    "                \n",
    "                # Create new Argument object with the approved changes\n",
    "                approved_argument = Argument(\n",
    "                    main_argument=main_point,\n",
    "                    argument_history=[],  # this needs to be populated with the corresponding argument history \n",
    "                    # it seems that using indices are reliable for history, so just give the Synthesizer.argument_history to the flagger\n",
    "                    # then it can populate this initialization accordingly and discard the old version of the argument (or, maybe you could just update the same Argument?)\n",
    "                    latest_relevance_score=float(metadata.get('relevanttius', '0')),\n",
    "                    latest_sources=sources,\n",
    "                    latest_change=metadata.get('muutokset', ''),\n",
    "                    latest_change_explained=metadata.get('perustelut', '')\n",
    "                )\n",
    "                approved_arguments.append(approved_argument)\n",
    "                print(\"Argument approved.\")\n",
    "            else:\n",
    "                print(\"Argument rejected.\")\n",
    "        \n",
    "        print(\"\\n=== Review Complete ===\")\n",
    "        return {\"approved\": approved_arguments, \"rejected\": flagged_arguments}\n",
    "\n",
    "    def _parse_sources(self, traceability_text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Parse the traceability text to extract source comments.\n",
    "        \n",
    "        Args:\n",
    "            traceability_text: The text from the Jäljitettävyys field\n",
    "            \n",
    "        Returns:\n",
    "            List of source comments\n",
    "        \"\"\"\n",
    "        # Split the text by common separators to extract sources\n",
    "        separators = [',', ';', '\\n']\n",
    "        for sep in separators:\n",
    "            if sep in traceability_text:\n",
    "                return [source.strip() for source in traceability_text.split(sep)] # not yet fully error-proof but good enough for now\n",
    "            \n",
    "    async def process_arguments(self, \n",
    "                              argument_analysis: Dict[str, List[Dict[str, str]]], \n",
    "                              new_argument_texts: List[str]) -> List[Argument]:\n",
    "        \"\"\"\n",
    "        Main method to process arguments through flagging and admin review.\n",
    "        \n",
    "        Args:\n",
    "            argument_analysis: Dictionary containing argument analyses and batch summary\n",
    "            saved_arguments: List of previously saved Argument objects\n",
    "            new_argument_texts: List of new argument main points\n",
    "            \n",
    "        Returns:\n",
    "            List of approved Argument objects\n",
    "        \"\"\"\n",
    "        # Flag arguments that need review\n",
    "        flagged_args = self.flag_low_relevance_arguments(\n",
    "            argument_analysis, \n",
    "            new_argument_texts\n",
    "        )\n",
    "        \n",
    "        # Get admin confirmation and return approved Argument objects\n",
    "        return await self.get_confirmation_from_admin(flagged_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BECAUSE THE INIT IS EMPTY, WE CAN MAKE THIS INTO AN OBJECT\n",
    "class OutputParser:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "\n",
    "    # -----------------------\n",
    "    # INITIAL BATCH parsing\n",
    "    # -----------------------\n",
    "\n",
    "    def parse_arguments_from_init(self, response: str) -> List[str]:\n",
    "        \"\"\"Extract argument main points from LLM response.\"\"\"\n",
    "        pattern = r'<ARGUMENTS>(.*?)</ARGUMENTS>'\n",
    "        match = re.search(pattern, response, re.DOTALL)\n",
    "        if not match:\n",
    "            return []\n",
    "\n",
    "        arguments = []\n",
    "        for line in match.group(1).strip().split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith('ARGUMENTTI '): # Check for index? And maybe use latest_index + 1, if no index\n",
    "                colon_index = line.find(':')\n",
    "                if colon_index != -1:\n",
    "                    arguments.append(line[colon_index + 1:].strip())\n",
    "        \n",
    "        return arguments\n",
    "\n",
    "    # -----------------------\n",
    "    # SYNTHESIS parsing\n",
    "    # -----------------------\n",
    "\n",
    "    def parse_arguments_from_synthesis(self, response: str):\n",
    "        return self.parse_arguments_from_init(response) # currently identical implementation\n",
    "   \n",
    "    # -----------------------\n",
    "    # ANALYSIS parsing\n",
    "    # -----------------------\n",
    "    \n",
    "    def parse_arguments_from_analysis(self, analysis_text) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Parses the individual arguments' analysis section.\n",
    "        Returns a list of dictionaries where each dictionary represents a single argument.\n",
    "        \"\"\"\n",
    "        argument_pattern = re.compile(\n",
    "            r\"ARGUMENTTI (\\d+):\\s*\"\n",
    "            r\"Argumentaatio:\\s*(.*?)\\s*(?=Jäljitettävyys:)\"\n",
    "            r\"Jäljitettävyys:\\s*(.*?)\\s*(?=Muutokset:)\"\n",
    "            r\"Muutokset:\\s*(.*?)\\s*(?=Relevanttius:)\"\n",
    "            r\"Relevanttius:\\s*(.*?)\\s*(?=Perustelut:)\"\n",
    "            r\"Perustelut:\\s*(.*?)\\s*(?=ARGUMENTTI|\\s*</ANALYYSI>)\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "        # Remove extra whitespace and normalize newlines\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', analysis_text).strip()\n",
    "            \n",
    "        matches = argument_pattern.finditer(cleaned_text)\n",
    "        arguments = []\n",
    "\n",
    "        for match in matches:\n",
    "            arguments.append({\n",
    "                \"index\": match.group(1),\n",
    "                \"argumentaatio\": match.group(2).strip(),\n",
    "                \"jaljitettavyys\": match.group(3).strip(),\n",
    "                \"muutokset\": match.group(4).strip(),\n",
    "                \"relevanttius\": match.group(5).strip(),\n",
    "                \"perustelut\": match.group(6).strip(),\n",
    "            })\n",
    "        return arguments\n",
    "\n",
    "    def parse_summary_from_analysis(self, analysis_text) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Parses the summary section of the output.\n",
    "        Returns a dictionary containing the summary information.\n",
    "        \"\"\"\n",
    "        summary_pattern = re.compile(\n",
    "            r\"<YHTEENVETO>\\s*\"\n",
    "            r\"Yhteenveto:\\s*\\[(.*?)\\]\\s*\"\n",
    "            r\"Perustelut:\\s*\\[(.*?)\\]\\s*\"\n",
    "            r\"Kehityskohteet:\\s*\\[(.*?)\\]\\s*</YHTEENVETO>\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "        match = summary_pattern.search(analysis_text)\n",
    "        \n",
    "        if match:\n",
    "            return {\n",
    "                \"yhteenveto\": match.group(1).strip(),\n",
    "                \"perustelut\": match.group(2).strip(),\n",
    "                \"kehityskohteet\": match.group(3).strip(),\n",
    "            }\n",
    "        return {}\n",
    "\n",
    "    def parse_analysis(self, analysis_text) -> Dict[str, List[Dict[str, str]]]:\n",
    "        \"\"\"\n",
    "        Combines the parsed arguments and summary into a single structure.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"arguments\": self.parse_arguments_from_analysis(analysis_text),\n",
    "            \"summary\": self.parse_summary_from_analysis(analysis_text), # although parse_summary returns Dict[str, str], not List[Dict[str, str]]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgumentSynthesizer:\n",
    "    def __init__(self, llm_provider, batch_size, flagger, parser):\n",
    "        self.parser = parser # would be nice to have types for parsers, flaggers and providers in this code... (now Any)\n",
    "        self.flagger = flagger\n",
    "        self.llm_provider = llm_provider\n",
    "        self.batch_size = batch_size\n",
    "        self.current_arguments: List[Argument] = []\n",
    "        self.output_history = []\n",
    "        self.input_history = []\n",
    "        self.n_iterations = 0\n",
    "        \n",
    "        # Template for initial argument creation, now in Finnish with more flexible argument count\n",
    "        self.INITIAL_TEMPLATE = \"\"\"\n",
    "            ### Ohjeet:\n",
    "            1. Käy läpi seuraavat kommentit aiheesta: \"{topic}\"\n",
    "            2. Muodosta 2-5 pääargumenttia, jotka kuvaavat keskeisiä näkökulmia aiheeseen:\n",
    "            - Pidä argumentit tiiviinä, jotta ne edustavat selkeästi erottuvaa näkökantaa\n",
    "            - Argumenttien tulisi yhdessä kattaa kaikki kommenteissa mainitut ajatukset\n",
    "            - Jos kommenteissa esiintyy uusi näkökulma, suosi uuden argumentin luomista vanhojen muokkaamisen sijaan\n",
    "            - Varmista, että argumentit on kirjoitettu selkeästi ja kattavasti\n",
    "            3. Huomioi erityisesti:\n",
    "            - Argumenttien määrä riippuu kommenttien sisällön monipuolisuudesta\n",
    "            - On parempi luoda useita tiiviitä argumentteja kuin pieni määrä liian pitkiä argumentteja\n",
    "\n",
    "            ### Analysoitavat kommentit:\n",
    "            {comments_text}\n",
    "\n",
    "            ### Tulostusmuoto:\n",
    "            <ARGUMENTS>\n",
    "            ARGUMENTTI 1: [Ensimmäinen kattava argumentti]\n",
    "            ARGUMENTTI 2: [Toinen kattava argumentti]\n",
    "            ARGUMENTTI 2: [Kolmas kattava argumentti]\n",
    "            </ARGUMENTS>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Template for synthesis, also in Finnish\n",
    "        self.SYNTHESIS_TEMPLATE = \"\"\"\n",
    "            ### Ohjeet:\n",
    "            1. Käy läpi nykyiset argumentit ja uudet kommentit aiheesta: \"{topic}\"\n",
    "            2. Kehitä ja täydennä argumenttirakennetta:\n",
    "            - Pidä argumentit tiiviinä, jotta ne edustavat selkeästi erottuvaa näkökantaa\n",
    "            - Jaa argumentit, jos ne sisältävät selvästi erillisiä näkökantoja\n",
    "            - Luo uusia argumentteja, jos kommentit paljastavat käsittelemättömiä näkökulmia\n",
    "            - Mikäli uusi näkökanta liittyy johonkin aiempaan argumenttiin vahvasti, muokkaa olemassa olevia argumentteja kuvaamaan paremmin keskustelun koko laajuutta\n",
    "            3. Tärkeää:\n",
    "            - Argumenttien lopullinen määrä määräytyy sisällön perusteella\n",
    "            - Päätös vanhan argumentin muokkaamisen ja uuden argumentin luomisen välillä riippuu siitä, kuinka helposti uuden näkökulman voi sitoa vanhaan argumenttiin tekemättä argumentista liian pitkää\n",
    "            - Jokaisen argumentin tulee olla selkeästi erillinen muista argumenteista\n",
    "\n",
    "            ### Nykyiset argumentit:\n",
    "            {existing_arguments}\n",
    "\n",
    "            ### Uudet kommentit:\n",
    "            {new_comments}\n",
    "\n",
    "            ### Tulostusmuoto:\n",
    "            <ARGUMENTS>\n",
    "            ARGUMENTTI 1: [Päivitetty argumentti]\n",
    "            ARGUMENTTI 2: [Päivitetty argumentti]\n",
    "            ARGUMENTTI 3: [Sama argumentti kuin aiemmin]\n",
    "            ARGUMENTTI 4: [Päivitetty argumentti]\n",
    "            ARGUMENTTI 5: [Sama argumentti kuin aiemmin]\n",
    "            ARGUMENTTI 6: [Täysin uusi argumentti]\n",
    "            </ARGUMENTS>\n",
    "        \"\"\"\n",
    "\n",
    "        self.BATCH_VALIDATION_TEMPLATE = \"\"\"\n",
    "            ### Ohjeet:\n",
    "            1. Käy läpi seuraavat kommentit ja vanhat sekä uudet argumentit aiheesta: \"{topic}\".\n",
    "            2. Arvioi uudet argumentit yksitellen seuraavien kohtien mukaan:\n",
    "            - Jäljitettävyys: Kirjaa, mitkä kommentit vaikuttivat kunkin muuttuneen argumentin muutoksiin. Tai jos uskot argumentin olevan täysin uusi, kirjaa se.\n",
    "            - Muutokset: Ilmoita, mitä lisäyksiä, poistamisia tai muutoksia argumentissa on tehty. Jos argumentti on täysin uusi, voit jättää tämän kohdan tyhjäksi.\n",
    "            - Relevanttius: Anna jokaiselle argumentille pisteytys asteikolla 1-10 sen mukaan, kuinka hyvin muutokset vastaavat käytettyjä kommentteja. Tai jos argumentti on täysin uusi, arvioi sen relevanssi kommentteihin.\n",
    "            3. Luo yleinen tiivistelmä: Luo lyhyt, korkeatasoinen yhteenveto koko analysoidusta erästä. Mitä pääkohtia huomioit kommenteissa, ja miten argumentit ovat kehittyneet niiden mukaan?\n",
    "            4. Ehdota kehityskohteita. Muotoile parannusehdotukset siten, että ne ovat ohje seuraavaa chatbotin suorittamaa analyysia varten.\n",
    "            \n",
    "            ### Analysoitavat tiedot:\n",
    "            Kommentit:\n",
    "            {comments_text}\n",
    "\n",
    "            Vanhat argumentit:\n",
    "            {old_arguments_text}\n",
    "\n",
    "            Uudet argumentit:\n",
    "            {new_arguments_text}\n",
    "\n",
    "            ### Tulostusmuoto:\n",
    "            <ANALYYSI>\n",
    "            ARGUMENTTI 1:\n",
    "            Argumentaatio: [Argumentin pääsisältö]\n",
    "            Jäljitettävyys: [Kommentit, jotka vaikuttivat muutoksiin (jätä tyhjäksi, jos uusi argumentti)]\n",
    "            Muutokset: [Mitkä asiat muuttuivat]\n",
    "            Relevanttius: [Relevanssipisteytys 1-10]\n",
    "            Perustelut: [Perustelut annetuille pisteille]\n",
    "            ARGUMENTTI 2:\n",
    "            Argumentaatio: [Argumentin pääsisältö]\n",
    "            Jäljitettävyys: [Kommentit, jotka vaikuttivat muutoksiin (jätä tyhjäksi, jos uusi argumentti)]\n",
    "            Muutokset: [Mitkä asiat muuttuivat]\n",
    "            Relevanttius: [Relevanssipisteytys 1-10]\n",
    "            Perustelut: [Perustelut annetuille pisteille]\n",
    "            </ANALYYSI>\n",
    "\n",
    "            <YHTEENVETO>\n",
    "            Yhteenveto: [Yleinen yhteenveto argumenttien muutoksista, poistoista ja lisäyksistä]\n",
    "            Perustelut: [Millä tavalla eri muutokset on perusteltu]\n",
    "            Kehityskohteet: [Parannusehdotukset]\n",
    "            </YHTEENVETO>\n",
    "        \"\"\"\n",
    "\n",
    "    async def process_comments(self, comments: List[str], topic: str, use_analysis: bool) -> List[Argument]:\n",
    "        \"\"\"Process all comments in batches, focusing on argument evolution.\"\"\"\n",
    "        \n",
    "        # Process initial batch to create 2-4 arguments\n",
    "        if not self.current_arguments:\n",
    "            initial_batch = comments[:self.batch_size]\n",
    "            await self._process_initial_batch(initial_batch, topic)\n",
    "        \n",
    "        # Process remaining batches\n",
    "        for i in range(self.batch_size, len(comments), self.batch_size):\n",
    "            batch = comments[i:i + self.batch_size]\n",
    "            await self._synthesize_batch(batch, topic, use_analysis)\n",
    "            \n",
    "        return self.current_arguments\n",
    "\n",
    "    async def _process_initial_batch(self, comments: List[str], topic: str):\n",
    "        \"\"\"Generate initial set of 2-4 arguments from first batch of comments.\"\"\"\n",
    "        comments_text = \"\\n\".join(f\"Kommentti {i+1}: {comment}\" \n",
    "                                for i, comment in enumerate(comments))\n",
    "        \n",
    "        prompt = self.INITIAL_TEMPLATE.format(\n",
    "            topic=topic,\n",
    "            comments_text=comments_text\n",
    "        )\n",
    "        \n",
    "        response = await self.llm_provider.generate([Message(Role.USER, prompt)])\n",
    "        new_arguments = self.parser.parse_arguments_from_init(response.content)\n",
    "        \n",
    "        # Save input and output for future analysis\n",
    "        self.output_history.append(response.content)\n",
    "        self.input_history.append(prompt)\n",
    "\n",
    "        # Create initial arguments\n",
    "        self.current_arguments = [\n",
    "            Argument(\n",
    "                main_argument=arg,\n",
    "                argument_history=[], \n",
    "                latest_relevance_score=0, # placeholder for initialization\n",
    "                latest_sources=[],\n",
    "                latest_change=\"Initial creation\",\n",
    "                latest_change_explained=\"Initial creation\"\n",
    "            ) for arg in new_arguments\n",
    "        ]\n",
    "\n",
    "        self.n_iterations += 1\n",
    "\n",
    "    async def _synthesize_batch(self, new_comments: List[str], topic: str, use_analysis: bool) -> List[Argument]:\n",
    "        \"\"\"Synthesize new comments with existing arguments.\"\"\"\n",
    "        current_args_text = \"\\n\".join(\n",
    "            f\"Argumentti {i+1}: {arg.main_argument}\" \n",
    "            for i, arg in enumerate(self.current_arguments)\n",
    "        )\n",
    "        \n",
    "        new_comments_text = \"\\n\".join(\n",
    "            f\"Kommentti {i+1}: {comment}\" \n",
    "            for i, comment in enumerate(new_comments)\n",
    "        )\n",
    "        \n",
    "        prompt = self.SYNTHESIS_TEMPLATE.format(\n",
    "            topic=topic,\n",
    "            existing_arguments=current_args_text,\n",
    "            new_comments=new_comments_text\n",
    "        )\n",
    "        \n",
    "        response = await self.llm_provider.generate([Message(Role.USER, prompt)])\n",
    "        new_argument_points = self.parser.parse_arguments_from_synthesis(response.content)\n",
    "\n",
    "        # Save input and output for future analysis\n",
    "        self.output_history.append(response.content)\n",
    "        self.input_history.append(prompt)\n",
    "        \n",
    "        # TO DO: make \n",
    "        if use_analysis:\n",
    "            await self.analyze_arguments(new_argument_points, new_comments, topic) # maybe break this into two parts: \n",
    "\n",
    "        self.n_iterations += 1\n",
    "        return [] # placeholder for now, but should return \n",
    "\n",
    "    async def analyze_arguments(self, new_argument_points: List[str], new_comments: List[str], topic) -> List[str]:\n",
    "        \"\"\"Use an LLM to analyze the arguments and provide feedback.\"\"\"\n",
    "        # populate the template with the arguments and comments\n",
    "        old_arguments_text = \"\\n\".join(\n",
    "            f\"Vanha argumentti {i+1}: {arg}\" \n",
    "            for i, arg in enumerate(self.current_arguments)\n",
    "        )\n",
    "\n",
    "        comments_text = \"\\n\".join(f\"Kommentti {i+1}: {comment}\" \n",
    "            for i, comment in enumerate(new_comments))\n",
    "\n",
    "        new_arguments_text = \"\\n\".join(\n",
    "            f\"Uusi argumentti {i+1}: {arg}\" \n",
    "            for i, arg in enumerate(new_argument_points)\n",
    "        )\n",
    "\n",
    "        prompt = self.BATCH_VALIDATION_TEMPLATE.format(\n",
    "            topic=topic,\n",
    "            comments_text=comments_text,\n",
    "            old_arguments_text=old_arguments_text,\n",
    "            new_arguments_text=new_arguments_text\n",
    "        )\n",
    "\n",
    "        response = await self.llm_provider.generate([Message(Role.USER, prompt)])\n",
    "        \n",
    "        # Save input and output for future analysis\n",
    "        self.output_history.append(response.content)\n",
    "        self.input_history.append(prompt)\n",
    "\n",
    "        # Parse the analysis text to get the arguments and summary\n",
    "        parsed_data = self.parser.parse_analysis(response.content) \n",
    "\n",
    "        # Flag arguments with low relevance for removal. Wait for user confirmation.\n",
    "        flagged_arguments = await self.flagger.process_arguments(argument_analysis=parsed_data, \n",
    "                                                      new_argument_texts=new_argument_points) # run this to see whether the flagging works\n",
    "        \n",
    "        # return the list of accepted strings (argument strings)\n",
    "\n",
    "\n",
    "    # Something to ponder for implementation later\n",
    "    async def get_argument_evolution_report(self) -> str: \n",
    "        \"\"\"Generate a readable report of how arguments evolved throughout.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arguments used for flagging:\n",
      "  Argumentti 1: Pääomaverotuksen tulisi olla osittain kunnallista, mikä mahdollistaisi paikallisten tarpeiden huomioimisen. Veroprosentin tulisi kuitenkin olla matalampi ja portaaton, jotta se ei kohtele epäoikeudenmukaisesti esimerkiksi metsänomistajia, jotka voivat joutua maksamaan suuren osan tulostaan yhdessä vuodessa. Lisäksi on tärkeää, että veromalli ei rajoita työntekoa ja yrittämistä, sillä verotus on keskeinen tekijä vetovoimassa ja paikallisten palveluiden käytössä.\n",
      "  Argumentti 2: Suomi on jo tunnettu korkeasta progressiivisesta verotuksestaan, ja verotuksen lisääminen ei välttämättä tuo merkittäviä etuja kunnalliseen verokertymään, sillä eniten ansaitsevien osuus on pieni. Tämän vuoksi olisi tärkeämpää keskittyä kannustamaan kulutusta ja paikallisten palveluiden käyttöä. Verotuksen kiristäminen nykyisestä ei edistä kansalaisten ostovoimaa, joka on taloudellisen kasvun ja korkean työllisyyden edellytys.\n",
      "  Argumentti 3: Progressiivinen verotus on tärkeä osa suomalaista yhteiskuntaa, mutta sen rajoja tulisi miettiä tarkkaan, jotta se ei rankaise ahkeruutta tai vähennä ihmisten mahdollisuuksia ansaita. Tasapainoisen veropolitiikan tulisi tukea sekä yhteiskunnallista hyvinvointia että yksilöiden taloudellista toimintaa. Nykyinen malli on toimiva, ja eniten ansaitsevat maksavat jo nyt suhteessa enemmän veroa, vaikka pienituloiset eivät maksa ollenkaan.\n",
      "  Argumentti 4: Kuntaverotus Suomessa on suhteellinen, eli sama prosentti kaikilta, mutta erilaisten vähennysten vuoksi paremmin ansaitsevat maksavat käytännössä enemmän kuin pienituloiset. Tämä on oikeudenmukaista, ja nykytilanne voidaan nähdä hyvänä, sillä eniten ansaitsevat käyttävät suhteessa vähemmän kunnallisia terveyspalveluja, mikä luo työtä. Kunta on kaikkien kunta, eikä verotuksen eriyttäminen ole tasa-arvoista.\n",
      "  Argumentti 5: Kansalaisten hyvä ostovoima on meidän kaikkien yhteinen etu, ja taloudellisen kasvun sekä korkean työllisyyden edellytys. Verotuksen nostaminen nykyisestä ei edistä tätä, eikä se näin ollen ole kestävä ratkaisu kunnan tuottamien palvelujen ja muiden menojen rahoittamiseksi.\n",
      "  Argumentti 6: Kuntatalous hyötyy, kun verotuksen sijaan keskitytään talouden kiertoon ja kulutukseen. Raha, joka jää kansalaisten käyttöön, siirtyy paikallisiin palveluihin ja yrityksiin, mikä vahvistaa työllisyyttä ja kuntataloutta kokonaisuudessaan. Talouden pyörät pyörimään - raha tuottaa, kun se kiertää kunnissa.\n",
      "\n",
      " Flagger: an analysis argument matched the input argument\n",
      "So, this string stayed the same: Pääomaverotuksen tulisi olla osittain kunnallista, mikä mahdollistaisi paikallisten tarpeiden huomioimisen. Veroprosentin tulisi kuitenkin olla matalampi ja portaaton, jotta se ei kohtele epäoikeudenmukaisesti esimerkiksi metsänomistajia, jotka voivat joutua maksamaan suuren osan tulostaan yhdessä vuodessa. Lisäksi on tärkeää, että veromalli ei rajoita työntekoa ja yrittämistä, sillä verotus on keskeinen tekijä vetovoimassa ja paikallisten palveluiden käytössä.\n",
      "\n",
      "Comparing relevance score of 9.0 to threshold 8\n",
      "\n",
      " Flagger: an analysis argument matched the input argument\n",
      "So, this string stayed the same: Suomi on jo tunnettu korkeasta progressiivisesta verotuksestaan, ja verotuksen lisääminen ei välttämättä tuo merkittäviä etuja kunnalliseen verokertymään, sillä eniten ansaitsevien osuus on pieni. Tämän vuoksi olisi tärkeämpää keskittyä kannustamaan kulutusta ja paikallisten palveluiden käyttöä. Verotuksen kiristäminen nykyisestä ei edistä kansalaisten ostovoimaa, joka on taloudellisen kasvun ja korkean työllisyyden edellytys.\n",
      "\n",
      "Comparing relevance score of 10.0 to threshold 8\n",
      "\n",
      " Flagger: an analysis argument matched the input argument\n",
      "So, this string stayed the same: Progressiivinen verotus on tärkeä osa suomalaista yhteiskuntaa, mutta sen rajoja tulisi miettiä tarkkaan, jotta se ei rankaise ahkeruutta tai vähennä ihmisten mahdollisuuksia ansaita. Tasapainoisen veropolitiikan tulisi tukea sekä yhteiskunnallista hyvinvointia että yksilöiden taloudellista toimintaa. Nykyinen malli on toimiva, ja eniten ansaitsevat maksavat jo nyt suhteessa enemmän veroa, vaikka pienituloiset eivät maksa ollenkaan.\n",
      "\n",
      "Comparing relevance score of 8.0 to threshold 8\n",
      "\n",
      " Flagger: an analysis argument matched the input argument\n",
      "So, this string stayed the same: Kuntaverotus Suomessa on suhteellinen, eli sama prosentti kaikilta, mutta erilaisten vähennysten vuoksi paremmin ansaitsevat maksavat käytännössä enemmän kuin pienituloiset. Tämä on oikeudenmukaista, ja nykytilanne voidaan nähdä hyvänä, sillä eniten ansaitsevat käyttävät suhteessa vähemmän kunnallisia terveyspalveluja, mikä luo työtä. Kunta on kaikkien kunta, eikä verotuksen eriyttäminen ole tasa-arvoista.\n",
      "\n",
      "Comparing relevance score of 9.0 to threshold 8\n",
      "\n",
      " Flagger: an analysis argument matched the input argument\n",
      "So, this string stayed the same: Kansalaisten hyvä ostovoima on meidän kaikkien yhteinen etu, ja taloudellisen kasvun sekä korkean työllisyyden edellytys. Verotuksen nostaminen nykyisestä ei edistä tätä, eikä se näin ollen ole kestävä ratkaisu kunnan tuottamien palvelujen ja muiden menojen rahoittamiseksi.\n",
      "\n",
      "Comparing relevance score of 8.0 to threshold 8\n",
      "\n",
      " Flagger: an analysis argument matched the input argument\n",
      "So, this string stayed the same: Kuntatalous hyötyy, kun verotuksen sijaan keskitytään talouden kiertoon ja kulutukseen. Raha, joka jää kansalaisten käyttöön, siirtyy paikallisiin palveluihin ja yrityksiin, mikä vahvistaa työllisyyttä ja kuntataloutta kokonaisuudessaan. Talouden pyörät pyörimään - raha tuottaa, kun se kiertää kunnissa.\n",
      "\n",
      "Comparing relevance score of 9.0 to threshold 8\n",
      "\n",
      "Flagged arguments: []\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = \"gpt-4o-mini-2024-07-18\" # fast and cheap\n",
    "# model=\"gpt-4o-2024-11-20\"      # slow, expensive, but powerful\n",
    "openai_provider = OpenAIProvider(api_key, model)\n",
    "data_source_path = os.path.join(parent_dir, 'data', 'sources', 'kuntavaalit2021.csv')\n",
    "output_path = os.path.join(parent_dir, 'condensation', 'results', 'current_results', 'v0_results.txt')\n",
    "n_comments = 20\n",
    "batch_size = 10\n",
    "relevance_threshold = 8\n",
    "topic = \"?\"\n",
    "\n",
    "# NOT IN USE YET BUT USEFUL\n",
    "# Choose a subset of comments to process\n",
    "\"\"\"question_index = 10\n",
    "explanation_column_name = f'q{question_index}.explanation_fi'\n",
    "likert_column_name = f'q{question_index}.answer' \"\"\"\n",
    "\n",
    "# get comments\n",
    "df = pd.read_csv(data_source_path)\n",
    "comment_indices = df['q9.explanation_fi'].dropna()[:n_comments].index.tolist()\n",
    "comments = df.loc[comment_indices, 'q9.explanation_fi'].tolist()\n",
    "\n",
    "# process arguments\n",
    "parser = OutputParser()\n",
    "flagger = ArgumentFlaggingSystem(relevance_threshold)\n",
    "processor = ArgumentSynthesizer(openai_provider, batch_size, flagger, parser)\n",
    "argument_analysis = await processor.process_comments(comments,topic, True)\n",
    "\n",
    "# print results\n",
    "lol = \"\"\" for arg in arguments:\n",
    "    print(arg.main_argument)\n",
    "    print(arg.argument_history)\n",
    "    print() \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
